{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def load_and_process_data():\n",
        "    url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "\n",
        "    print(f\"Downloading dataset from {url}...\")\n",
        "    try:\n",
        "        data = pd.read_csv(url)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading data: {e}\")\n",
        "        print(\"Please ensure you have internet access or the URL is correct.\")\n",
        "        return None\n",
        "\n",
        "    target_col = 'Class'\n",
        "    if target_col not in data.columns:\n",
        "        target_col = data.columns[-1]\n",
        "\n",
        "    X = data.drop(target_col, axis=1)\n",
        "    y = data[target_col]\n",
        "\n",
        "    print(f\"Original dataset shape: {data.shape}\")\n",
        "    print(f\"Original class distribution:\\n{y.value_counts()}\")\n",
        "\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "    balanced_df = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "\n",
        "    print(f\"Balanced dataset shape: {balanced_df.shape}\")\n",
        "    print(f\"Balanced class distribution:\\n{balanced_df[target_col].value_counts()}\")\n",
        "\n",
        "    return balanced_df, target_col\n",
        "\n",
        "def calculate_sample_size(N, confidence_level=0.95, margin_of_error=0.05, p=0.5):\n",
        "    z_score_map = {0.90: 1.645, 0.95: 1.96, 0.99: 2.576}\n",
        "    Z = z_score_map.get(confidence_level, 1.96)\n",
        "\n",
        "    n0 = (Z**2 * p * (1-p)) / (margin_of_error**2)\n",
        "\n",
        "    n = n0 / (1 + ((n0 - 1) / N))\n",
        "\n",
        "    return int(math.ceil(n))\n",
        "\n",
        "def simple_random_sampling(df, n, random_state=42):\n",
        "    return df.sample(n=n, random_state=random_state)\n",
        "\n",
        "def systematic_sampling(df, n, random_state=42):\n",
        "    step = len(df) // n\n",
        "    start = np.random.randint(0, step)\n",
        "    indices = np.arange(start, len(df), step)\n",
        "    return df.iloc[indices].head(n)\n",
        "\n",
        "def stratified_sampling(df, n, target_col, random_state=42):\n",
        "    return df.groupby(target_col, group_keys=False).apply(lambda x: x.sample(int(n/2), random_state=random_state))\n",
        "\n",
        "def cluster_sampling(df, n, random_state=42):\n",
        "    k = 20\n",
        "    df_temp = df.copy()\n",
        "    df_temp['cluster_id'] = np.random.randint(0, k, size=len(df))\n",
        "\n",
        "    clusters_needed = max(1, int(n / (len(df)/k)))\n",
        "    selected_clusters = np.random.choice(k, clusters_needed, replace=False)\n",
        "\n",
        "    sample = df_temp[df_temp['cluster_id'].isin(selected_clusters)]\n",
        "    return sample.drop('cluster_id', axis=1)\n",
        "\n",
        "def bootstrap_sampling(df, n, random_state=42):\n",
        "    return df.sample(n=n, replace=True, random_state=random_state)\n",
        "\n",
        "def main():\n",
        "    balanced_df, target_col = load_and_process_data()\n",
        "    if balanced_df is None:\n",
        "        return\n",
        "\n",
        "    N = len(balanced_df)\n",
        "    sample_size = calculate_sample_size(N, confidence_level=0.95, margin_of_error=0.05)\n",
        "    print(f\"\\nCalculated Sample Size (95% Conf, 5% Error): {sample_size}\")\n",
        "\n",
        "    samplings = {\n",
        "        \"Simple Random\": lambda df: simple_random_sampling(df, sample_size),\n",
        "        \"Systematic\": lambda df: systematic_sampling(df, sample_size),\n",
        "        \"Stratified\": lambda df: stratified_sampling(df, sample_size, target_col),\n",
        "        \"Cluster\": lambda df: cluster_sampling(df, sample_size),\n",
        "        \"Bootstrap\": lambda df: bootstrap_sampling(df, sample_size)\n",
        "    }\n",
        "\n",
        "    models = {\n",
        "        \"M1 (Logistic Regression)\": LogisticRegression(max_iter=1000),\n",
        "        \"M2 (Decision Tree)\": DecisionTreeClassifier(random_state=42),\n",
        "        \"M3 (Random Forest)\": RandomForestClassifier(random_state=42),\n",
        "        \"M4 (SVM)\": SVC(),\n",
        "        \"M5 (KNN)\": KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    X = balanced_df.drop(target_col, axis=1)\n",
        "    y = balanced_df[target_col]\n",
        "\n",
        "    X_pool, X_test, y_pool, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    pool_df = pd.concat([X_pool, y_pool], axis=1)\n",
        "\n",
        "    results = {model_name: {} for model_name in models.keys()}\n",
        "\n",
        "    print(\"\\nStarting Model Evaluation...\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for sample_name, sampler_func in samplings.items():\n",
        "        print(f\"Processing {sample_name} Sampling...\")\n",
        "\n",
        "        sample_df = sampler_func(pool_df)\n",
        "\n",
        "        X_sample = sample_df.drop(target_col, axis=1)\n",
        "        y_sample = sample_df[target_col]\n",
        "\n",
        "        for model_name, model in models.items():\n",
        "            try:\n",
        "                model.fit(X_sample, y_sample)\n",
        "                preds = model.predict(X_test)\n",
        "                acc = accuracy_score(y_test, preds)\n",
        "                results[model_name][sample_name] = acc * 100\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {model_name} on {sample_name}: {e}\")\n",
        "                results[model_name][sample_name] = np.nan\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "    print(\"\\nFinal Accuracy Table (%):\")\n",
        "\n",
        "    results_df = pd.DataFrame(results).T\n",
        "    cols = [\"Simple Random\", \"Systematic\", \"Stratified\", \"Cluster\", \"Bootstrap\"]\n",
        "    available_cols = [c for c in cols if c in results_df.columns]\n",
        "    results_df = results_df[available_cols]\n",
        "\n",
        "    print(results_df)\n",
        "\n",
        "    results_df.to_csv(\"sampling_assignment_results.csv\")\n",
        "    print(\"\\nResults saved to 'sampling_assignment_results.csv'\")\n",
        "\n",
        "    print(\"\\n--- Summary ---\")\n",
        "    for model in results_df.index:\n",
        "        best_sampling = results_df.loc[model].idxmax()\n",
        "        best_acc = results_df.loc[model].max()\n",
        "        print(f\"For {model}, best technique: {best_sampling} ({best_acc:.2f}%)者にしました。\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv...\n",
            "Original dataset shape: (772, 31)\n",
            "Original class distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "Balanced dataset shape: (1526, 31)\n",
            "Balanced class distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Calculated Sample Size (95% Conf, 5% Error): 308\n",
            "\n",
            "Starting Model Evaluation...\n",
            "--------------------------------------------------------------------------------\n",
            "Processing Simple Random Sampling...\n",
            "Processing Systematic Sampling...\n",
            "Processing Stratified Sampling...\n",
            "Processing Cluster Sampling...\n",
            "Processing Bootstrap Sampling...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Final Accuracy Table (%):\n",
            "                          Simple Random  Systematic  Stratified    Cluster  \\\n",
            "M1 (Logistic Regression)      92.483660   90.522876   90.196078  85.947712   \n",
            "M2 (Decision Tree)            98.039216   96.405229   95.751634  96.732026   \n",
            "M3 (Random Forest)            99.346405   99.346405   99.019608  99.673203   \n",
            "M4 (SVM)                      65.686275   63.398693   63.725490  64.052288   \n",
            "M5 (KNN)                      93.790850   93.137255   93.137255  92.810458   \n",
            "\n",
            "                          Bootstrap  \n",
            "M1 (Logistic Regression)  92.810458  \n",
            "M2 (Decision Tree)        97.385621  \n",
            "M3 (Random Forest)        99.019608  \n",
            "M4 (SVM)                  65.686275  \n",
            "M5 (KNN)                  93.137255  \n",
            "\n",
            "Results saved to 'sampling_assignment_results.csv'\n",
            "\n",
            "--- Summary ---\n",
            "For M1 (Logistic Regression), best technique: Bootstrap (92.81%)者にしました。\n",
            "For M2 (Decision Tree), best technique: Simple Random (98.04%)者にしました。\n",
            "For M3 (Random Forest), best technique: Cluster (99.67%)者にしました。\n",
            "For M4 (SVM), best technique: Simple Random (65.69%)者にしました。\n",
            "For M5 (KNN), best technique: Simple Random (93.79%)者にしました。\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnHyKm9stYs",
        "outputId": "307a6fa3-5924-46bd-ed5b-2f96f328f23c"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}